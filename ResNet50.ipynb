{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "# Diretórios\n",
    "train_dir = './data/train'\n",
    "val_dir = './data/val'\n",
    "test_dir = './data/test'\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "\n",
    "# Carregamento dos dados\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir, image_size=img_size, batch_size=batch_size, label_mode='categorical')\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir, image_size=img_size, batch_size=batch_size, label_mode='categorical')\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir, image_size=img_size, batch_size=batch_size, label_mode='categorical')\n",
    "\n",
    "class_names = test_ds.class_names\n",
    "\n",
    "# Pré-processamento\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(data_augmentation(x)), y)).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Modelo base ResNet50\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Cabeça do modelo\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compilação inicial\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\"best_resnet_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "# Treinamento inicial\n",
    "history_initial = model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
    "                            callbacks=[early_stop])\n",
    "\n",
    "# Fine-tuning: liberar todas as camadas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompilar com taxa de aprendizado menor\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinamento com fine-tuning + melhorias\n",
    "history_finetune = model.fit(train_ds, validation_data=val_ds, initial_epoch=10, epochs=25,\n",
    "                             callbacks=[early_stop, lr_scheduler, checkpoint])\n",
    "\n",
    "# Avaliação final\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"\\n✅ Final Test Accuracy (ResNet50): {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após o treinamento\n",
    "model.save(\"resnet50_finetuned_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss'] + history_finetune.history['loss']\n",
    "val_loss = history.history['val_loss'] + history_finetune.history['val_loss'] \n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss, label='Treino')\n",
    "plt.plot(val_loss, label='Validação')\n",
    "plt.title('Evolução da perda (loss)')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"\\n✅ Test Accuracy (ResNet50): {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
